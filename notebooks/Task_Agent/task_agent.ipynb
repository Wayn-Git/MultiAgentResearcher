{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9734a15b",
   "metadata": {},
   "source": [
    "Importing requried libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb3d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pprint\n",
    "import json\n",
    "import re\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52c3dc8",
   "metadata": {},
   "source": [
    "Taking user input + the research context [Research context needs to be improved or reimplimented]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8416a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------Cell 2----------\n",
    "\n",
    "\n",
    "user_input = \"research on iphones\"\n",
    "research_context = \"Starting fresh research\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db43b46d",
   "metadata": {},
   "source": [
    "Defining the necessary paths where the data needs to be stored for the other models to access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a75d09f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------Paths----------\n",
    "\n",
    "task_data_path = \"../../model_output_data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa435cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "research_on_iphones\n"
     ]
    }
   ],
   "source": [
    "#-------Cleaning Input For Folder Name-------\n",
    "\n",
    "lower_user_input = user_input.lower()\n",
    "\n",
    "# Matches any character NOT in the range a-z, A-Z, or 0-9\n",
    "cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]+', '', lower_user_input)\n",
    "\n",
    "folder_name_for_query = re.sub(r\"\\s+\", \"_\", cleaned_text)\n",
    "\n",
    "print(folder_name_for_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80ca7be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../model_output_data/research_on_iphones\n",
      "Created folder: ../../model_output_data/research_on_iphones\n"
     ]
    }
   ],
   "source": [
    "\n",
    "complete_data_path_query = task_data_path + folder_name_for_query\n",
    "\n",
    "print(complete_data_path_query)\n",
    "if not os.path.exists(complete_data_path_query):\n",
    "    os.makedirs(complete_data_path_query, exist_ok=True)\n",
    "    print(f\"Created folder: {complete_data_path_query}\")\n",
    "else:\n",
    "    print(f\"Folder already exists: {complete_data_path_query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e622b7eb",
   "metadata": {},
   "source": [
    "Temporary Storage List to ensure the LLM remembers the previous conversation with the user\n",
    "\n",
    "[This could possibly be removed and be implimented in further model as the user won't really interact with this specific agent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "235964b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "# MAX_MESSAGES = 10   # total, user + assistant\n",
    "\n",
    "\n",
    "\n",
    "# if len(messages) > MAX_MESSAGES:\n",
    "#     messages = messages[-MAX_MESSAGES:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0e5a58",
   "metadata": {},
   "source": [
    "The system prompt that tells the LLM what it's actual purpose is so it doesn't get out of track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad24f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "You are creating an initial research plan for the topic: \"{user_input}\"\n",
    "Initial Query: \"{user_input}\"\n",
    "Research Context: {research_context if research_context else \"Starting fresh research\"}\n",
    "Decompose this query into 3–5 actionable research tasks. Return a JSON array with each task having:\n",
    "• \"description\": Clear, actionable task (string)\n",
    "• \"priority\": 1–10 (integer, higher = more important, default=5)\n",
    "• \"type\": \"research\" (always \"research\")\n",
    "\n",
    "STRICTLY CREATE ONLY 3-5 ACTIONABLE RESEARCH TASKS\n",
    "\n",
    "Focus on: understanding the topic, gathering information, identifying key aspects, and building foundational knowledge.\n",
    "Example for \"Impacts of Generative AI on Scientific Research\":\n",
    "<answer>\n",
    "[\n",
    "{{\"description\": \"Survey major applications of generative AI in scientific discovery\", \"priority\": 8, \"type\": \"research\"}},\n",
    "{{\"description\": \"Identify key papers and institutions leading AI-assisted science research\", \"priority\": 7, \"type\": \"research\"}},\n",
    "{{\"description\": \"Examine methodological advances enabled by generative models in ...\", \"priority\": 6, \"type\": \"research\"}},\n",
    "{{\"description\": \"Assess challenges and ethical considerations of AI-generated scientific results\", \"priority\": 5, \"type\": \"research\"}}\n",
    "]\n",
    "</answer>\n",
    "CRITICAL: Wrap JSON in <answer>tags.\n",
    "Output ONLY valid JSON.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "messages.append({\"role\": \"system\", \"content\": system_prompt})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0487420b",
   "metadata": {},
   "source": [
    "First Agent by groq, the task agent: Responsible for creating tasks for the user query for the next model to find information for the tasks\n",
    "\n",
    "Model Used: llama-3.1-8b-instant\n",
    "Why ? Faster Responses, bigger context window and great in text generation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ada5669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<answer>\n",
      "[\n",
      "  {\"description\": \"Conduct a literature review on the history of iPhone development, from the first iPhone in 2007 to the latest models\", \"priority\": 6, \"type\": \"research\"},\n",
      "  {\"description\": \"Identify and analyze key iPhone features and technologies (e.g., Touch ID, Face ID, camera advancements)\", \"priority\": 7, \"type\": \"research\"},\n",
      "  {\"description\": \"Study market trends and sales data of iPhone models to understand consumer preferences and market share \", \"priority\": 5, \"type\": \"research\"},\n",
      "  {\"description\": \"Explore the impact of iPhones on mobile software development, including apps, games, and services\", \"priority\": 8, \"type\": \"research\"},\n",
      "  {\"description\": \"Research the environmental and social implications of iPhone production and usage (e.g., e-waste, supply chains, labor practices)\", \"priority\": 4, \"type\": \"research\"}\n",
      "]\n",
      "</answer>\n"
     ]
    }
   ],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": user_input}) \n",
    "\n",
    "task_agent = Groq()\n",
    "completion = task_agent.chat.completions.create(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    messages=messages,\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "reply = completion.choices[0].message.content\n",
    "print(reply)\n",
    "messages.append({\"role\": \"assistant\", \"content\": reply})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a94c4ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<answer>\n",
      "[\n",
      "  {\"description\": \"Conduct a literature review on the history of iPhone development, from the first iPhone in 2007 to the latest models\", \"priority\": 6, \"type\": \"research\"},\n",
      "  {\"description\": \"Identify and analyze key iPhone features and technologies (e.g., Touch ID, Face ID, camera advancements)\", \"priority\": 7, \"type\": \"research\"},\n",
      "  {\"description\": \"Study market trends and sales data of iPhone models to understand consumer preferences and market share \", \"priority\": 5, \"type\": \"research\"},\n",
      "  {\"description\": \"Explore the impact of iPhones on mobile software development, including apps, games, and services\", \"priority\": 8, \"type\": \"research\"},\n",
      "  {\"description\": \"Research the environmental and social implications of iPhone production and usage (e.g., e-waste, supply chains, labor practices)\", \"priority\": 4, \"type\": \"research\"}\n",
      "]\n",
      "</answer>\n"
     ]
    }
   ],
   "source": [
    "print(messages[-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dbea301",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_output = messages[-1][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651083ec",
   "metadata": {},
   "source": [
    "Appending the generated tasks to a json file for the other model to make use of the generated tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a432476b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'description': 'Conduct a literature review on the history of iPhone development, from the first iPhone in 2007 to the latest models', 'priority': 6, 'type': 'research'}, {'description': 'Identify and analyze key iPhone features and technologies (e.g., Touch ID, Face ID, camera advancements)', 'priority': 7, 'type': 'research'}, {'description': 'Study market trends and sales data of iPhone models to understand consumer preferences and market share ', 'priority': 5, 'type': 'research'}, {'description': 'Explore the impact of iPhones on mobile software development, including apps, games, and services', 'priority': 8, 'type': 'research'}, {'description': 'Research the environmental and social implications of iPhone production and usage (e.g., e-waste, supply chains, labor practices)', 'priority': 4, 'type': 'research'}]\n"
     ]
    }
   ],
   "source": [
    "start = assistant_output.find(\"<answer>\") + len(\"<answer>\")\n",
    "end = assistant_output.find(\"</answer>\")\n",
    "\n",
    "json_text = assistant_output[start:end].strip()\n",
    "\n",
    "tasks = json.loads(json_text)\n",
    "\n",
    "with open(os.path.join(complete_data_path_query, \"tasks.json\"), \"w\") as f:\n",
    "    json.dump(tasks, f, indent=4)\n",
    "\n",
    "print(tasks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
